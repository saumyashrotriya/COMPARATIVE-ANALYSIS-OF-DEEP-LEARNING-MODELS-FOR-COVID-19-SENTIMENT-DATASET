{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN-LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDo5xHOep-M_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "outputId": "a9f88b35-5513-43c9-b541-da4e11a7f769"
      },
      "source": [
        "\n",
        "!wget -P /root/input/ -c \"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-06-04 06:11:55--  https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.8.230\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.8.230|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1647046227 (1.5G) [application/x-gzip]\n",
            "Saving to: ‘/root/input/GoogleNews-vectors-negative300.bin.gz’\n",
            "\n",
            "GoogleNews-vectors- 100%[===================>]   1.53G  45.0MB/s    in 36s     \n",
            "\n",
            "2020-06-04 06:12:31 (44.1 MB/s) - ‘/root/input/GoogleNews-vectors-negative300.bin.gz’ saved [1647046227/1647046227]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Nu-mdSFowON",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f306c607-abfe-4eb8-b3a0-5b75dcc052fa"
      },
      "source": [
        "\n",
        "import gensim.models.keyedvectors as word2vec \n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.layers import LSTM, Conv1D, Dense, Flatten, MaxPooling1D, Dropout\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, roc_curve,  roc_auc_score, classification_report\n",
        "\n",
        "\n",
        "import logging\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from matplotlib import pyplot\n",
        "from numpy import array\n",
        "\n",
        "\n",
        "logging.basicConfig(format='%(asctime)s : %(levelname) s : %(message)s', level=logging.INFO)\n",
        "\n",
        "\n",
        "np.random.seed(24)\n",
        "\n",
        "tweetsData = pd.read_csv('coronatweets.csv') \n",
        "tweetsData.head()\n",
        "\n",
        "\n",
        "tweets = tweetsData['full_text']\n",
        "labels = tweetsData['sent_score']\n",
        "\n",
        "\n",
        "labels_count = labels.value_counts()\n",
        "labels_count.plot(kind=\"bar\")\n",
        "print(labels.value_counts())\n",
        "\n",
        "\n",
        "tkr = RegexpTokenizer('[a-zA-Z@]+')\n",
        "\n",
        "tweets_split = []\n",
        "\n",
        "for i, line in enumerate(tweets):\n",
        "   tweet = str(line).lower().split()\n",
        "   tweet = tkr.tokenize(str(tweet))\n",
        "   tweets_split.append(tweet)\n",
        "\n",
        "print(tweets_split[1])\n",
        "\n",
        "\n",
        "\n",
        "w2vModel = word2vec.KeyedVectors.load_word2vec_format('https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz', binary=True, limit=50000)\n",
        "\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(tweets_split)\n",
        "X = tokenizer.texts_to_sequences(tweets_split)\n",
        "\n",
        "\n",
        "maxlentweet = 30\n",
        "\n",
        "X = pad_sequences(X, maxlen=maxlentweet)\n",
        "print(X.shape)\n",
        "\n",
        "\n",
        "embedding_layer = Embedding(input_dim=w2vModel.syn0.shape[0], output_dim=w2vModel.syn0.shape[1], weights=[w2vModel.syn0], \n",
        "                            input_length=X.shape[1])\n",
        "\n",
        "\n",
        "lstm_out = 150\n",
        "\n",
        "model = Sequential()\n",
        "model.add(embedding_layer)\n",
        "model.add(Conv1D(filters=64, kernel_size=5, activation='relu', padding='causal'))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Dropout(0.7))\n",
        "model.add(LSTM(units=lstm_out))\n",
        "model.add(Dropout(0.7))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, labels, test_size= 0.1, random_state = 24)\n",
        "\n",
        "\n",
        "batch_size = 40\n",
        "history=model.fit(X_train, Y_train, epochs=100, verbose=1, batch_size=batch_size, validation_split=0.2)     \n",
        "\n",
        "\n",
        "score, acc = model.evaluate(X_test, Y_test, verbose = 2, batch_size=batch_size)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "\n",
        "from matplotlib import pyplot\n",
        "from numpy import array\n",
        "\n",
        "#pyplot.plot(history.history['loss'])\n",
        "#pyplot.plot(history.history['val_loss'])\n",
        "#pyplot.title('model train vs validation loss')\n",
        "#pyplot.ylabel('loss')\n",
        "#pyplot.xlabel('epoch')\n",
        "#pyplot.ylim(-4, 0)\n",
        "#pyplot.xlim(0, 10)\n",
        "\n",
        "#pyplot.legend(['train', 'validation'], loc='upper right')\n",
        "#pyplot.show()\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " 1    6252\n",
            "-1    4210\n",
            " 0    1583\n",
            "Name: sent_score, dtype: int64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-06-04 06:12:36,486 : INFO : loading projection weights from https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "['itali', 'prove', 'pc', 'sometim', 'danger', 'note', 'covid', 'case', 'soar', 'sadli', 'idiot', 'hug', 'chines', 'day', 'meanwhil', 'chines', 'gov', 'use', 'propaganda', 'corona', 'chineseviru']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n",
            "2020-06-04 06:12:38,654 : INFO : loaded (50000, 300) matrix from https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(12045, 30)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:72: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 30, 300)           15000000  \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 30, 64)            96064     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 15, 64)            0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 15, 64)            0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 150)               129000    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 150)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 151       \n",
            "=================================================================\n",
            "Total params: 15,225,215\n",
            "Trainable params: 15,225,215\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 8672 samples, validate on 2168 samples\n",
            "Epoch 1/100\n",
            "8672/8672 [==============================] - 57s 7ms/step - loss: 0.3921 - accuracy: 0.1463 - val_loss: -0.1716 - val_accuracy: 0.3086\n",
            "Epoch 2/100\n",
            "8672/8672 [==============================] - 59s 7ms/step - loss: -4.1581 - accuracy: 0.3953 - val_loss: -4.0597 - val_accuracy: 0.3399\n",
            "Epoch 3/100\n",
            "8672/8672 [==============================] - 57s 7ms/step - loss: -14.4928 - accuracy: 0.4765 - val_loss: -8.2734 - val_accuracy: 0.3967\n",
            "Epoch 4/100\n",
            "8672/8672 [==============================] - 58s 7ms/step - loss: -26.1491 - accuracy: 0.5092 - val_loss: -11.9439 - val_accuracy: 0.4059\n",
            "Epoch 5/100\n",
            "8672/8672 [==============================] - 61s 7ms/step - loss: -38.0972 - accuracy: 0.5212 - val_loss: -16.7362 - val_accuracy: 0.4253\n",
            "Epoch 6/100\n",
            "8672/8672 [==============================] - 62s 7ms/step - loss: -50.3199 - accuracy: 0.5401 - val_loss: -18.9603 - val_accuracy: 0.4184\n",
            "Epoch 7/100\n",
            "8672/8672 [==============================] - 62s 7ms/step - loss: -62.6030 - accuracy: 0.5542 - val_loss: -23.3929 - val_accuracy: 0.4317\n",
            "Epoch 8/100\n",
            "8672/8672 [==============================] - 65s 8ms/step - loss: -73.8932 - accuracy: 0.5643 - val_loss: -26.7365 - val_accuracy: 0.4391\n",
            "Epoch 9/100\n",
            "8672/8672 [==============================] - 53s 6ms/step - loss: -84.4224 - accuracy: 0.5682 - val_loss: -30.3065 - val_accuracy: 0.4410\n",
            "Epoch 10/100\n",
            "8672/8672 [==============================] - 53s 6ms/step - loss: -96.1425 - accuracy: 0.5728 - val_loss: -34.9315 - val_accuracy: 0.4520\n",
            "Epoch 11/100\n",
            "8672/8672 [==============================] - 53s 6ms/step - loss: -107.7278 - accuracy: 0.5804 - val_loss: -38.8080 - val_accuracy: 0.4410\n",
            "Epoch 12/100\n",
            "8672/8672 [==============================] - 55s 6ms/step - loss: -118.8833 - accuracy: 0.5800 - val_loss: -42.1342 - val_accuracy: 0.4673\n",
            "Epoch 13/100\n",
            "8672/8672 [==============================] - 53s 6ms/step - loss: -128.5034 - accuracy: 0.5808 - val_loss: -47.0243 - val_accuracy: 0.4497\n",
            "Epoch 14/100\n",
            "8672/8672 [==============================] - 53s 6ms/step - loss: -139.6849 - accuracy: 0.5920 - val_loss: -50.1489 - val_accuracy: 0.4534\n",
            "Epoch 15/100\n",
            "8672/8672 [==============================] - 52s 6ms/step - loss: -150.1485 - accuracy: 0.5836 - val_loss: -51.1596 - val_accuracy: 0.4377\n",
            "Epoch 16/100\n",
            "8672/8672 [==============================] - 52s 6ms/step - loss: -160.6234 - accuracy: 0.5849 - val_loss: -55.5952 - val_accuracy: 0.4589\n",
            "Epoch 17/100\n",
            "8672/8672 [==============================] - 52s 6ms/step - loss: -170.6838 - accuracy: 0.5903 - val_loss: -54.4841 - val_accuracy: 0.4184\n",
            "Epoch 18/100\n",
            "8672/8672 [==============================] - 52s 6ms/step - loss: -179.4122 - accuracy: 0.5808 - val_loss: -62.9349 - val_accuracy: 0.4534\n",
            "Epoch 19/100\n",
            "8672/8672 [==============================] - 52s 6ms/step - loss: -189.6992 - accuracy: 0.5853 - val_loss: -66.1018 - val_accuracy: 0.4479\n",
            "Epoch 20/100\n",
            "8672/8672 [==============================] - 52s 6ms/step - loss: -199.9935 - accuracy: 0.5883 - val_loss: -69.0398 - val_accuracy: 0.4557\n",
            "Epoch 21/100\n",
            "8672/8672 [==============================] - 52s 6ms/step - loss: -211.1302 - accuracy: 0.5893 - val_loss: -76.0532 - val_accuracy: 0.4410\n",
            "Epoch 22/100\n",
            "8672/8672 [==============================] - 52s 6ms/step - loss: -220.9918 - accuracy: 0.5869 - val_loss: -72.0402 - val_accuracy: 0.4271\n",
            "Epoch 23/100\n",
            "8672/8672 [==============================] - 52s 6ms/step - loss: -230.7549 - accuracy: 0.5898 - val_loss: -78.6251 - val_accuracy: 0.4368\n",
            "Epoch 24/100\n",
            "8672/8672 [==============================] - 54s 6ms/step - loss: -239.4982 - accuracy: 0.5898 - val_loss: -81.5075 - val_accuracy: 0.4497\n",
            "Epoch 25/100\n",
            "8672/8672 [==============================] - 52s 6ms/step - loss: -250.1849 - accuracy: 0.5901 - val_loss: -86.5883 - val_accuracy: 0.4493\n",
            "Epoch 26/100\n",
            "8672/8672 [==============================] - 52s 6ms/step - loss: -259.9255 - accuracy: 0.5918 - val_loss: -90.9547 - val_accuracy: 0.4405\n",
            "Epoch 27/100\n",
            "8672/8672 [==============================] - 52s 6ms/step - loss: -269.7195 - accuracy: 0.5891 - val_loss: -90.5420 - val_accuracy: 0.4603\n",
            "Epoch 28/100\n",
            "8672/8672 [==============================] - 52s 6ms/step - loss: -280.5132 - accuracy: 0.5894 - val_loss: -94.7734 - val_accuracy: 0.4511\n",
            "Epoch 29/100\n",
            "8672/8672 [==============================] - 52s 6ms/step - loss: -289.7242 - accuracy: 0.5890 - val_loss: -95.5121 - val_accuracy: 0.4525\n",
            "Epoch 30/100\n",
            "8672/8672 [==============================] - 52s 6ms/step - loss: -299.5785 - accuracy: 0.5914 - val_loss: -98.2959 - val_accuracy: 0.4405\n",
            "Epoch 31/100\n",
            "8672/8672 [==============================] - 52s 6ms/step - loss: -310.8750 - accuracy: 0.5959 - val_loss: -104.3813 - val_accuracy: 0.4396\n",
            "Epoch 32/100\n",
            "8672/8672 [==============================] - 52s 6ms/step - loss: -319.3087 - accuracy: 0.5917 - val_loss: -104.0023 - val_accuracy: 0.4465\n",
            "Epoch 33/100\n",
            "8672/8672 [==============================] - 52s 6ms/step - loss: -329.2486 - accuracy: 0.5949 - val_loss: -94.9526 - val_accuracy: 0.4756\n",
            "Epoch 34/100\n",
            "8672/8672 [==============================] - 52s 6ms/step - loss: -339.3716 - accuracy: 0.5976 - val_loss: -105.1652 - val_accuracy: 0.4419\n",
            "Epoch 35/100\n",
            "8672/8672 [==============================] - 54s 6ms/step - loss: -350.0965 - accuracy: 0.5958 - val_loss: -102.9046 - val_accuracy: 0.4396\n",
            "Epoch 36/100\n",
            "8672/8672 [==============================] - 52s 6ms/step - loss: -358.3375 - accuracy: 0.5995 - val_loss: -109.0869 - val_accuracy: 0.4433\n",
            "Epoch 37/100\n",
            "8672/8672 [==============================] - 52s 6ms/step - loss: -371.4949 - accuracy: 0.5974 - val_loss: -108.9994 - val_accuracy: 0.4433\n",
            "Epoch 38/100\n",
            "8672/8672 [==============================] - 52s 6ms/step - loss: -379.2525 - accuracy: 0.6012 - val_loss: -118.3435 - val_accuracy: 0.4562\n",
            "Epoch 39/100\n",
            "8672/8672 [==============================] - 52s 6ms/step - loss: -388.3154 - accuracy: 0.5999 - val_loss: -121.8179 - val_accuracy: 0.4511\n",
            "Epoch 40/100\n",
            "8672/8672 [==============================] - 52s 6ms/step - loss: -400.7765 - accuracy: 0.5994 - val_loss: -123.3033 - val_accuracy: 0.4673\n",
            "Epoch 41/100\n",
            "8672/8672 [==============================] - 52s 6ms/step - loss: -408.8739 - accuracy: 0.5989 - val_loss: -121.8304 - val_accuracy: 0.4299\n",
            "Epoch 42/100\n",
            "8672/8672 [==============================] - 53s 6ms/step - loss: -417.1869 - accuracy: 0.6008 - val_loss: -132.4603 - val_accuracy: 0.4470\n",
            "Epoch 43/100\n",
            "8672/8672 [==============================] - 53s 6ms/step - loss: -429.8646 - accuracy: 0.6001 - val_loss: -137.5378 - val_accuracy: 0.4576\n",
            "Epoch 44/100\n",
            "8672/8672 [==============================] - 52s 6ms/step - loss: -437.0633 - accuracy: 0.5948 - val_loss: -138.6236 - val_accuracy: 0.4585\n",
            "Epoch 45/100\n",
            "8672/8672 [==============================] - 52s 6ms/step - loss: -448.8412 - accuracy: 0.6024 - val_loss: -139.6804 - val_accuracy: 0.4534\n",
            "Epoch 46/100\n",
            "8672/8672 [==============================] - 52s 6ms/step - loss: -458.4933 - accuracy: 0.6006 - val_loss: -142.3941 - val_accuracy: 0.4580\n",
            "Epoch 47/100\n",
            "8672/8672 [==============================] - 55s 6ms/step - loss: -466.9690 - accuracy: 0.5980 - val_loss: -142.9130 - val_accuracy: 0.4585\n",
            "Epoch 48/100\n",
            "8672/8672 [==============================] - 53s 6ms/step - loss: -476.6377 - accuracy: 0.5963 - val_loss: -145.6834 - val_accuracy: 0.4525\n",
            "Epoch 49/100\n",
            "8672/8672 [==============================] - 52s 6ms/step - loss: -486.0253 - accuracy: 0.5952 - val_loss: -153.5438 - val_accuracy: 0.4659\n",
            "Epoch 50/100\n",
            "8672/8672 [==============================] - 52s 6ms/step - loss: -497.9593 - accuracy: 0.6045 - val_loss: -153.0611 - val_accuracy: 0.4530\n",
            "Epoch 51/100\n",
            "8672/8672 [==============================] - 52s 6ms/step - loss: -506.7592 - accuracy: 0.6032 - val_loss: -150.5934 - val_accuracy: 0.4520\n",
            "Epoch 52/100\n",
            "8672/8672 [==============================] - 52s 6ms/step - loss: -517.7875 - accuracy: 0.6037 - val_loss: -154.2872 - val_accuracy: 0.4640\n",
            "Epoch 53/100\n",
            "8672/8672 [==============================] - 52s 6ms/step - loss: -527.4083 - accuracy: 0.6038 - val_loss: -159.0110 - val_accuracy: 0.4622\n",
            "Epoch 54/100\n",
            "8672/8672 [==============================] - 53s 6ms/step - loss: -536.1672 - accuracy: 0.6084 - val_loss: -156.7814 - val_accuracy: 0.4622\n",
            "Epoch 55/100\n",
            "8672/8672 [==============================] - 53s 6ms/step - loss: -545.3027 - accuracy: 0.6062 - val_loss: -158.3081 - val_accuracy: 0.4649\n",
            "Epoch 56/100\n",
            "8672/8672 [==============================] - 53s 6ms/step - loss: -558.6238 - accuracy: 0.6018 - val_loss: -170.6558 - val_accuracy: 0.4530\n",
            "Epoch 57/100\n",
            "8672/8672 [==============================] - 54s 6ms/step - loss: -565.5354 - accuracy: 0.6000 - val_loss: -170.7138 - val_accuracy: 0.4585\n",
            "Epoch 58/100\n",
            "8672/8672 [==============================] - 56s 6ms/step - loss: -577.3436 - accuracy: 0.6029 - val_loss: -180.4848 - val_accuracy: 0.4571\n",
            "Epoch 59/100\n",
            "8672/8672 [==============================] - 54s 6ms/step - loss: -586.6342 - accuracy: 0.6010 - val_loss: -180.1708 - val_accuracy: 0.4534\n",
            "Epoch 60/100\n",
            "8672/8672 [==============================] - 54s 6ms/step - loss: -595.4947 - accuracy: 0.6104 - val_loss: -182.2898 - val_accuracy: 0.4516\n",
            "Epoch 61/100\n",
            "8672/8672 [==============================] - 54s 6ms/step - loss: -607.2526 - accuracy: 0.6090 - val_loss: -173.8382 - val_accuracy: 0.4566\n",
            "Epoch 62/100\n",
            "8672/8672 [==============================] - 54s 6ms/step - loss: -615.1452 - accuracy: 0.6122 - val_loss: -181.4436 - val_accuracy: 0.4562\n",
            "Epoch 63/100\n",
            "8672/8672 [==============================] - 54s 6ms/step - loss: -625.8818 - accuracy: 0.6099 - val_loss: -188.6940 - val_accuracy: 0.4520\n",
            "Epoch 64/100\n",
            "8672/8672 [==============================] - 54s 6ms/step - loss: -637.2261 - accuracy: 0.6065 - val_loss: -193.1505 - val_accuracy: 0.4525\n",
            "Epoch 65/100\n",
            "8672/8672 [==============================] - 54s 6ms/step - loss: -643.9621 - accuracy: 0.6065 - val_loss: -191.6069 - val_accuracy: 0.4534\n",
            "Epoch 66/100\n",
            "8672/8672 [==============================] - 54s 6ms/step - loss: -654.5707 - accuracy: 0.6063 - val_loss: -193.6818 - val_accuracy: 0.4373\n",
            "Epoch 67/100\n",
            "8672/8672 [==============================] - 53s 6ms/step - loss: -663.7276 - accuracy: 0.6093 - val_loss: -196.8910 - val_accuracy: 0.4534\n",
            "Epoch 68/100\n",
            "8672/8672 [==============================] - 54s 6ms/step - loss: -674.3975 - accuracy: 0.6145 - val_loss: -197.2105 - val_accuracy: 0.4511\n",
            "Epoch 69/100\n",
            "8672/8672 [==============================] - 54s 6ms/step - loss: -685.5054 - accuracy: 0.6130 - val_loss: -199.4684 - val_accuracy: 0.4608\n",
            "Epoch 70/100\n",
            "8672/8672 [==============================] - 56s 6ms/step - loss: -693.2688 - accuracy: 0.6116 - val_loss: -198.6674 - val_accuracy: 0.4502\n",
            "Epoch 71/100\n",
            "8672/8672 [==============================] - 53s 6ms/step - loss: -704.8770 - accuracy: 0.6134 - val_loss: -195.5336 - val_accuracy: 0.4714\n",
            "Epoch 72/100\n",
            "8672/8672 [==============================] - 54s 6ms/step - loss: -712.7974 - accuracy: 0.6150 - val_loss: -208.9155 - val_accuracy: 0.4442\n",
            "Epoch 73/100\n",
            "8672/8672 [==============================] - 53s 6ms/step - loss: -723.9038 - accuracy: 0.6136 - val_loss: -201.7229 - val_accuracy: 0.4719\n",
            "Epoch 74/100\n",
            "8672/8672 [==============================] - 53s 6ms/step - loss: -729.9429 - accuracy: 0.6084 - val_loss: -204.1209 - val_accuracy: 0.4497\n",
            "Epoch 75/100\n",
            "8672/8672 [==============================] - 53s 6ms/step - loss: -743.9853 - accuracy: 0.6116 - val_loss: -209.1107 - val_accuracy: 0.4576\n",
            "Epoch 76/100\n",
            "8672/8672 [==============================] - 53s 6ms/step - loss: -755.0709 - accuracy: 0.6128 - val_loss: -212.9697 - val_accuracy: 0.4539\n",
            "Epoch 77/100\n",
            "8672/8672 [==============================] - 53s 6ms/step - loss: -763.9808 - accuracy: 0.6113 - val_loss: -210.6450 - val_accuracy: 0.4488\n",
            "Epoch 78/100\n",
            "8672/8672 [==============================] - 53s 6ms/step - loss: -773.2648 - accuracy: 0.6165 - val_loss: -211.6227 - val_accuracy: 0.4543\n",
            "Epoch 79/100\n",
            "8672/8672 [==============================] - 53s 6ms/step - loss: -779.7764 - accuracy: 0.6120 - val_loss: -225.1452 - val_accuracy: 0.4553\n",
            "Epoch 80/100\n",
            "8672/8672 [==============================] - 53s 6ms/step - loss: -793.8513 - accuracy: 0.6115 - val_loss: -228.8415 - val_accuracy: 0.4603\n",
            "Epoch 81/100\n",
            "8672/8672 [==============================] - 55s 6ms/step - loss: -801.6258 - accuracy: 0.6152 - val_loss: -237.0527 - val_accuracy: 0.4433\n",
            "Epoch 82/100\n",
            "8672/8672 [==============================] - 53s 6ms/step - loss: -811.5494 - accuracy: 0.6136 - val_loss: -229.8507 - val_accuracy: 0.4663\n",
            "Epoch 83/100\n",
            "8672/8672 [==============================] - 53s 6ms/step - loss: -825.1488 - accuracy: 0.6131 - val_loss: -231.9240 - val_accuracy: 0.4543\n",
            "Epoch 84/100\n",
            "8672/8672 [==============================] - 53s 6ms/step - loss: -833.0265 - accuracy: 0.6181 - val_loss: -235.2451 - val_accuracy: 0.4626\n",
            "Epoch 85/100\n",
            "8672/8672 [==============================] - 53s 6ms/step - loss: -842.6416 - accuracy: 0.6144 - val_loss: -241.2438 - val_accuracy: 0.4636\n",
            "Epoch 86/100\n",
            "8672/8672 [==============================] - 53s 6ms/step - loss: -849.7004 - accuracy: 0.6142 - val_loss: -247.7282 - val_accuracy: 0.4659\n",
            "Epoch 87/100\n",
            "8672/8672 [==============================] - 52s 6ms/step - loss: -862.3107 - accuracy: 0.6177 - val_loss: -245.6912 - val_accuracy: 0.4566\n",
            "Epoch 88/100\n",
            "8672/8672 [==============================] - 52s 6ms/step - loss: -873.2906 - accuracy: 0.6168 - val_loss: -245.8524 - val_accuracy: 0.4516\n",
            "Epoch 89/100\n",
            "8672/8672 [==============================] - 53s 6ms/step - loss: -878.8885 - accuracy: 0.6165 - val_loss: -247.2583 - val_accuracy: 0.4534\n",
            "Epoch 90/100\n",
            "8672/8672 [==============================] - 52s 6ms/step - loss: -888.7787 - accuracy: 0.6189 - val_loss: -250.9610 - val_accuracy: 0.4557\n",
            "Epoch 91/100\n",
            "8672/8672 [==============================] - 52s 6ms/step - loss: -899.1313 - accuracy: 0.6177 - val_loss: -245.9091 - val_accuracy: 0.4608\n",
            "Epoch 92/100\n",
            "8672/8672 [==============================] - 52s 6ms/step - loss: -906.4035 - accuracy: 0.6176 - val_loss: -266.3979 - val_accuracy: 0.4654\n",
            "Epoch 93/100\n",
            "8672/8672 [==============================] - 55s 6ms/step - loss: -919.3505 - accuracy: 0.6184 - val_loss: -266.8121 - val_accuracy: 0.4539\n",
            "Epoch 94/100\n",
            "8672/8672 [==============================] - 53s 6ms/step - loss: -937.8607 - accuracy: 0.6195 - val_loss: -270.7480 - val_accuracy: 0.4580\n",
            "Epoch 95/100\n",
            "8672/8672 [==============================] - 53s 6ms/step - loss: -941.5071 - accuracy: 0.6211 - val_loss: -267.4912 - val_accuracy: 0.4589\n",
            "Epoch 96/100\n",
            "8672/8672 [==============================] - 52s 6ms/step - loss: -950.9045 - accuracy: 0.6218 - val_loss: -268.6147 - val_accuracy: 0.4622\n",
            "Epoch 97/100\n",
            "8672/8672 [==============================] - 52s 6ms/step - loss: -960.2776 - accuracy: 0.6200 - val_loss: -272.0927 - val_accuracy: 0.4566\n",
            "Epoch 98/100\n",
            "8672/8672 [==============================] - 53s 6ms/step - loss: -968.6037 - accuracy: 0.6191 - val_loss: -275.5675 - val_accuracy: 0.4580\n",
            "Epoch 99/100\n",
            "8672/8672 [==============================] - 56s 6ms/step - loss: -979.6133 - accuracy: 0.6205 - val_loss: -276.1902 - val_accuracy: 0.4663\n",
            "Epoch 100/100\n",
            "8672/8672 [==============================] - 58s 7ms/step - loss: -993.4849 - accuracy: 0.6230 - val_loss: -291.2694 - val_accuracy: 0.4649\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAPhElEQVR4nO3dcayddX3H8fdHKrroZovcdaytK4mdBv9QyQ1gXJZNsrbAsvKHEswyGtKl/+Ci2ZJZ908zkAWzZEySSdJJt2KcSHCORomsqZplWYBehKFQWe8Q1jZAr7SwOaIO/O6P+6se672955bbc4q/9yu5Oc/z/f2e53yfnORznjznOeemqpAk9eE1425AkjQ6hr4kdcTQl6SOGPqS1BFDX5I6smzcDZzMueeeW2vXrh13G5L0qvLggw9+t6om5ho7o0N/7dq1TE1NjbsNSXpVSfLUfGNe3pGkjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI6c0d/IHbW127487hZOqydvumLcLUgaM8/0Jakjhr4kdcTQl6SOGPqS1JGhQj/J8iR3Jfl2kv1J3pPknCR7khxojyva3CS5Jcl0kkeSXDiwn81t/oEkm0/XQUmS5jbsmf4nga9U1duBdwL7gW3A3qpaB+xt6wCXAeva31bgVoAk5wDbgYuBi4Dtx98oJEmjsWDoJ3kT8JvAbQBV9cOqeh7YBOxq03YBV7blTcDtNes+YHmS84ANwJ6qOlpVx4A9wMYlPRpJ0kkNc6Z/PjAD/F2Sh5J8OskbgJVV9XSb8wywsi2vAg4ObH+o1ear/5QkW5NMJZmamZlZ3NFIkk5qmNBfBlwI3FpV7wb+l59cygGgqgqopWioqnZU1WRVTU5MzPkvHiVJp2iY0D8EHKqq+9v6Xcy+CTzbLtvQHo+08cPAmoHtV7fafHVJ0ogsGPpV9QxwMMnbWulS4DFgN3D8DpzNwN1teTdwTbuL5xLghXYZ6F5gfZIV7QPc9a0mSRqRYX9754+AzyY5G3gCuJbZN4w7k2wBngKuanPvAS4HpoEX21yq6miSG4B9bd71VXV0SY5CkjSUoUK/qh4GJucYunSOuQVcN89+dgI7F9OgJGnp+I1cSeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSR4YK/SRPJvlmkoeTTLXaOUn2JDnQHle0epLckmQ6ySNJLhzYz+Y2/0CSzafnkCRJ81nMmf5vV9W7qmqyrW8D9lbVOmBvWwe4DFjX/rYCt8LsmwSwHbgYuAjYfvyNQpI0Gq/k8s4mYFdb3gVcOVC/vWbdByxPch6wAdhTVUer6hiwB9j4Cp5fkrRIw4Z+Af+c5MEkW1ttZVU93ZafAVa25VXAwYFtD7XafPWfkmRrkqkkUzMzM0O2J0kaxrIh5/1GVR1O8svAniTfHhysqkpSS9FQVe0AdgBMTk4uyT4lSbOGOtOvqsPt8QjwRWavyT/bLtvQHo+06YeBNQObr261+eqSpBFZMPSTvCHJLx5fBtYD3wJ2A8fvwNkM3N2WdwPXtLt4LgFeaJeB7gXWJ1nRPsBd32qSpBEZ5vLOSuCLSY7P/4eq+kqSfcCdSbYATwFXtfn3AJcD08CLwLUAVXU0yQ3Avjbv+qo6umRHIkla0IKhX1VPAO+co/4ccOkc9QKum2dfO4Gdi29TkrQU/EauJHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6suA/RpdeLdZu+/K4WzitnrzpinG3oJ8DnulLUkcMfUnqiKEvSR0ZOvSTnJXkoSRfauvnJ7k/yXSSzyc5u9Vf19an2/jagX18rNUfT7JhqQ9GknRyiznT/zCwf2D9E8DNVfVW4BiwpdW3AMda/eY2jyQXAFcD7wA2Ap9KctYra1+StBhDhX6S1cAVwKfbeoD3AXe1KbuAK9vyprZOG7+0zd8E3FFVP6iq7wDTwEVLcRCSpOEMe6b/18CfAj9q628Gnq+ql9r6IWBVW14FHARo4y+0+T+uz7HNjyXZmmQqydTMzMwiDkWStJAFQz/J7wJHqurBEfRDVe2oqsmqmpyYmBjFU0pSN4b5ctZ7gd9LcjnweuCXgE8Cy5Msa2fzq4HDbf5hYA1wKMky4E3AcwP14wa3kSSNwIJn+lX1sapaXVVrmf0g9qtV9fvA14D3t2mbgbvb8u62Thv/alVVq1/d7u45H1gHPLBkRyJJWtAr+RmGjwJ3JPk48BBwW6vfBnwmyTRwlNk3Cqrq0SR3Ao8BLwHXVdXLr+D5JUmLtKjQr6qvA19vy08wx903VfV94APzbH8jcONim5QkLQ2/kStJHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SerIgqGf5PVJHkjy70keTfLnrX5+kvuTTCf5fJKzW/11bX26ja8d2NfHWv3xJBtO10FJkuY2zJn+D4D3VdU7gXcBG5NcAnwCuLmq3gocA7a0+VuAY61+c5tHkguAq4F3ABuBTyU5aykPRpJ0cguGfs36Xlt9bfsr4H3AXa2+C7iyLW9q67TxS5Ok1e+oqh9U1XeAaeCiJTkKSdJQhrqmn+SsJA8DR4A9wH8Cz1fVS23KIWBVW14FHARo4y8Abx6sz7HN4HNtTTKVZGpmZmbxRyRJmtdQoV9VL1fVu4DVzJ6dv/10NVRVO6pqsqomJyYmTtfTSFKXFnX3TlU9D3wNeA+wPMmyNrQaONyWDwNrANr4m4DnButzbCNJGoFh7t6ZSLK8Lf8C8DvAfmbD//1t2mbg7ra8u63Txr9aVdXqV7e7e84H1gEPLNWBSJIWtmzhKZwH7Gp32rwGuLOqvpTkMeCOJB8HHgJua/NvAz6TZBo4yuwdO1TVo0nuBB4DXgKuq6qXl/ZwJEkns2DoV9UjwLvnqD/BHHffVNX3gQ/Ms68bgRsX36YkaSn4jVxJ6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHFgz9JGuSfC3JY0keTfLhVj8nyZ4kB9rjilZPkluSTCd5JMmFA/va3OYfSLL59B2WJGkuw5zpvwT8SVVdAFwCXJfkAmAbsLeq1gF72zrAZcC69rcVuBVm3ySA7cDFwEXA9uNvFJKk0Vgw9Kvq6ar6Rlv+H2A/sArYBOxq03YBV7blTcDtNes+YHmS84ANwJ6qOlpVx4A9wMYlPRpJ0kkt6pp+krXAu4H7gZVV9XQbegZY2ZZXAQcHNjvUavPVJUkjMnToJ3kj8AXgI1X134NjVVVALUVDSbYmmUoyNTMzsxS7lCQ1Q4V+ktcyG/ifrap/bOVn22Ub2uORVj8MrBnYfHWrzVf/KVW1o6omq2pyYmJiMcciSVrAMHfvBLgN2F9VfzUwtBs4fgfOZuDugfo17S6eS4AX2mWge4H1SVa0D3DXt5okaUSWDTHnvcAfAN9M8nCr/RlwE3Bnki3AU8BVbewe4HJgGngRuBagqo4muQHY1+ZdX1VHl+QoJElDWTD0q+pfgcwzfOkc8wu4bp597QR2LqZBSdLS8Ru5ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4M841cSTqt1m778rhbOK2evOmKcbfwY57pS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6smDoJ9mZ5EiSbw3UzkmyJ8mB9rii1ZPkliTTSR5JcuHANpvb/ANJNp+ew5EkncwwZ/p/D2w8obYN2FtV64C9bR3gMmBd+9sK3AqzbxLAduBi4CJg+/E3CknS6CwY+lX1L8DRE8qbgF1teRdw5UD99pp1H7A8yXnABmBPVR2tqmPAHn72jUSSdJqd6jX9lVX1dFt+BljZllcBBwfmHWq1+eo/I8nWJFNJpmZmZk6xPUnSXF7xB7lVVUAtQS/H97ejqiaranJiYmKpditJ4tRD/9l22Yb2eKTVDwNrBuatbrX56pKkETrV0N8NHL8DZzNw90D9mnYXzyXAC+0y0L3A+iQr2ge461tNkjRCyxaakORzwG8B5yY5xOxdODcBdybZAjwFXNWm3wNcDkwDLwLXAlTV0SQ3APvavOur6sQPhyVJp9mCoV9VH5xn6NI55hZw3Tz72QnsXFR3kqQl5TdyJakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHRl56CfZmOTxJNNJto36+SWpZyMN/SRnAX8DXAZcAHwwyQWj7EGSejbqM/2LgOmqeqKqfgjcAWwacQ+S1K1lI36+VcDBgfVDwMWDE5JsBba21e8leXxEvY3DucB3R/Vk+cSonqkbvn6vXj/vr92vzTcw6tBfUFXtAHaMu49RSDJVVZPj7kOnxtfv1avn127Ul3cOA2sG1le3miRpBEYd+vuAdUnOT3I2cDWwe8Q9SFK3Rnp5p6peSvIh4F7gLGBnVT06yh7OMF1cxvo55uv36tXta5eqGncPkqQR8Ru5ktQRQ1+SOmLoS1JHzrj79CVpqSV5O7Pf/l/VSoeB3VW1f3xdjYdn+meAJNeOuwedmiRvHHcPOrkkH2X2J18CPND+Anyuxx999O6dM0CS/6qqt4y7Dy2er92ZL8l/AO+oqv87oX428GhVrRtPZ+Ph5Z0RSfLIfEPAylH2osVJ8sfzDQGe6Z/5fgT8KvDUCfXz2lhXDP3RWQlsAI6dUA/wb6NvR4vwF8BfAi/NMeYl0jPfR4C9SQ7wkx98fAvwVuBDY+tqTAz90fkS8MaqevjEgSRfH307WoRvAP9UVQ+eOJDkD8fQjxahqr6S5NeZ/Wn3wQ9y91XVy+PrbDy8pi8tIMnbgOeq6rsDtV+pqmeSrKyqZ8fYnrQohr50CpJ8o6ouHHcf0mJ5PVI6NRl3A9KpMPSlU/O3425AOhVe3pGkjnimL0kdMfQlqSOGviR1xNCXpI78P//KC2HqtLfzAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "he_vfI2-MPGt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22de912c-e34d-4842-a8a2-498292b4e64c"
      },
      "source": [
        "print(acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.4705394208431244\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o65ov3MLfxZi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-8I_7OteL3V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3vHhKrq9HNj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}